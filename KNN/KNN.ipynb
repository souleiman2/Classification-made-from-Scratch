{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importer les librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames, Distributions, Gadfly, GLM\n",
    "using Distances\n",
    "import StatsBase       # Pour la standardisation des variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traiter les données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(455, 10)\n",
      "(114, 10)\n"
     ]
    }
   ],
   "source": [
    "data = CSV.read(\"../train.csv\")\n",
    "y_train = data[end]\n",
    "\n",
    "temp_X_train = data[2:end-1] #omit id and diagnosis\n",
    "# Estimation des paramètres de la standardisation\n",
    "tx = StatsBase.fit(StatsBase.ZScoreTransform, Matrix{Float64}(temp_X_train), dims=1)\n",
    "# Standardisation des variables\n",
    "X_train = StatsBase.transform(tx, Matrix{Float64}(temp_X_train));\n",
    "\n",
    "data_test = CSV.read(\"../test.csv\")\n",
    "X_test = StatsBase.transform(tx, Matrix{Float64}(data_test[2:end]));\n",
    "\n",
    "id_test = data_test[1]\n",
    "\n",
    "\n",
    "println(size(X_train))\n",
    "println(size(X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faire le modele KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"KNN.csv\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function calculateDist(vec1, vec2)\n",
    "    return euclidean(vec1,vec2)\n",
    "end\n",
    "\n",
    "function findIndexesNBiggest(n, tab)\n",
    "    temp = copy(tab)\n",
    "    indexes = []\n",
    "    while (n > 0 && size(tab)[1] > 0)\n",
    "        _, index_smaller = findmin(temp)\n",
    "        push!(indexes, index_smaller)\n",
    "        splice!(temp, index_smaller)\n",
    "        n -= 1\n",
    "    end\n",
    "    return indexes\n",
    "end\n",
    "\n",
    "function predict(k, X_train, y_train, X_test) #works best with odd k    \n",
    "    nb_data = size(X_train)[1]\n",
    "    \n",
    "    distances = []\n",
    "    for elem in 1:nb_data\n",
    "        push!(distances, calculateDist(X_test, X_train[elem, :]))\n",
    "    end\n",
    "    \n",
    "    indexes_distances = findIndexesNBiggest(k, distances)\n",
    "    \n",
    "    nb_0 = 0\n",
    "    for index in indexes_distances\n",
    "        if (y_train[index] == 0)\n",
    "            nb_0 += 1\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return convert(Int8, (nb_0 < k - nb_0))\n",
    "    \n",
    "end\n",
    "\n",
    "function knn(k, X_train, y_train, X_test)\n",
    "    ans = []\n",
    "    for elem in 1:size(X_test)[1]\n",
    "        push!(ans, predict(k, X_train, y_train, X_test[elem, :]))\n",
    "    end\n",
    "    return ans\n",
    "end\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-cross validation\n",
    "function findAllIndexes(length, nb_blocks)\n",
    "    return [(convert(Int16, floor((i-1)*length/nb_blocks))+1, convert(Int16, floor(i*length/nb_blocks))) for i = 1:nb_blocks]\n",
    "end\n",
    "\n",
    "function countTFPN(t_label, predictions)\n",
    "    TP, FP, FN, TN = 0, 0, 0, 0\n",
    "    taille = size(t_label)[1]\n",
    "    for i = 1:taille\n",
    "        if(t_label[i] == 1 && predictions[i] == 1)\n",
    "            TP += 1\n",
    "        elseif(t_label[i] == 1 && predictions[i] == 0)\n",
    "            FN += 1\n",
    "        elseif(t_label[i] == 0 && predictions[i] == 1)\n",
    "            FP += 1\n",
    "        elseif(t_label[i] == 0 && predictions[i] == 0)\n",
    "            TN += 1\n",
    "        end\n",
    "            \n",
    "    end\n",
    "    return TP, FP, FN, TN\n",
    "end\n",
    "\n",
    "function computeMetrics(t_label, predictions)\n",
    "    TP, FP, FN, TN = countTFPN(t_label, predictions)\n",
    "    precision, recall, accuracy = (TP/(TP + FP)), (TP/(TP + FN)), ((TP+TN)/(TP + FP + FN + TN))\n",
    "    return [precision, recall, accuracy]\n",
    "end\n",
    "\n",
    "function split_train_test(X, y, index)\n",
    "    sub_X_train = [X[1 : index[1]-1, :]; X[index[2] : end, :]]\n",
    "    sub_X_test = X[index[1] : index[2], :]\n",
    "    sub_y_train = [y[1 : index[1]-1]; y[index[2] : end]]\n",
    "    true_y_test = y[index[1] : index[2]]\n",
    "    return sub_X_train, sub_X_test, sub_y_train, true_y_test\n",
    "end\n",
    "\n",
    "\n",
    "function KCrossValidation(k, X, y, nb_blocks = 5)\n",
    "    indexes = findAllIndexes(size(X_test)[1],nb_blocks)\n",
    "    ans = []\n",
    "    for interval = indexes\n",
    "        sub_X_train, sub_X_test, sub_y_train, true_y_test = split_train_test(X, y, interval)\n",
    "        sub_y_test =  knn(k, sub_X_train, sub_y_train, sub_X_test)\n",
    "        push!(ans, computeMetrics(true_y_test, sub_y_test))\n",
    "    end\n",
    "    temp = mean(ans)\n",
    "    return temp\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trouver le K qui minimise l'erreur selon les métriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = []\n",
    "gen_temp = 1:2:9\n",
    "for i = 1:2:9\n",
    "    temp = KCrossValidation(i, X_train, y_train)\n",
    "    if (i ==  1)\n",
    "        metrics = [[elem] for elem = temp]\n",
    "    else\n",
    "        taille = size(temp)[1]\n",
    "        for index = 1:taille\n",
    "            push!(metrics[index], temp[index])\n",
    "        end\n",
    "    end\n",
    "    \n",
    "end\n",
    "ks = [i for i = gen_temp]\n",
    "\n",
    "y_titles = [\"precision\", \"recall\", \"accuracy\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(x=ks, y=metrics[1], Geom.line, Guide.xlabel(\"K\"), Guide.ylabel(y_titles[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(x=ks, y=metrics[2], Geom.line, Guide.xlabel(\"K\"), Guide.ylabel(y_titles[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(x=ks, y=metrics[3], Geom.line, Guide.xlabel(\"K\"), Guide.ylabel(y_titles[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rouler le code avec ce K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 1\n",
    "y_test = knn(k, X_train, y_train, X_test)\n",
    "prediction = DataFrame(id = id_test, diagnosis = y_test)\n",
    "CSV.write(\"KNN.csv\",prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.5.1",
   "language": "julia",
   "name": "julia-1.5"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
