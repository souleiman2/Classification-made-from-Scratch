{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importer les librairies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "using CSV, DataFrames, Distributions, Gadfly, MLBase, Random, Statistics\n",
    "using GLM\n",
    "import StatsBase\n",
    "using LinearAlgebra\n",
    "include(\"functions.jl\")\n",
    "using Plots            # Pour la heatmap du KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualiser les données\n",
    "\n",
    "Avant toute chose, il est important de voir ce à quoi ressemble nos données et quelles sont les liens entre celles-ci pour essayer de mieux les comprendre. Pour ce faire, nous avons décidé de tracer les nuages de points pour chaque paire de variable explicatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img id=\"myimage\" src=\"pair.png\" style=\" height:500px; width:500px;\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"img-zoom-container\", style=\"overflow:auto; height:550px; width:5669px;\">\n",
    "  <img id=\"myimage\" src=\"pair.png\" style=\" height:5669px; width:5669px;\">>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CSV.read(\"train.csv\")\n",
    "\n",
    "Gadfly.set_default_plot_size(150cm, 150cm)\n",
    "\n",
    "matrix = Array{Plot}(undef, 10, 10)\n",
    "\n",
    "column = names(data)[2:end-1]\n",
    "i = 1\n",
    "for c1 in column\n",
    "    j = 1\n",
    "    for c2 in column\n",
    "        if (i == j)\n",
    "            matrix[i,j] = Gadfly.plot(data, x = c1, Geom.histogram(bincount = 30), color = :diagnosis)\n",
    "        else\n",
    "            matrix[i,j] = Gadfly.plot(data, x = c1, y = c2, color = :diagnosis)\n",
    "        end\n",
    "        j+=1\n",
    "    end \n",
    "    i+=1\n",
    "end \n",
    "\n",
    "#grid = gridstack(matrix) # graphing is so computationnally hard that it makes the jupyter bug\n",
    "println(\"Graphing is done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous remarquons plusieurs choses, premièrement, notre rayon semble avoir une relation directement proportionnelle avec le périmètre. De plus, l’air semble lié au rayon, par une relation exponentielle. Une forte relation exponentielle semble aussi exister entre la dimension fractale et le rayon. Nous voyons donc qu’il y aura forcément présence de colinéarité que nous pouvons éliminer à l’aide de la PCA."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1: KNN\n",
    "\n",
    "Le K-nearest neighbors algorithm est un algorithme de classification assez simple. Il se base sur le fait que les features points d'une classe devraient, généralement, se trouver proche des autres points de la même classe (ils devraient être clustered si nous normalisons les données). En se basant sur ce principe, un KNN va tout simplement prendre ces prédictions sur la distance que le point du testing set a avec les points du training set. Une fois que ces distances se font calculer, il faudra prendre les K points qui sont les plus proches du point à prédire. Grâce aux K points trouvés et à leurs classes respectives, nous allons pouvons classifier nos nouveaux points (les points du testing set).\n",
    "\n",
    "Avant de réaliser le KNN, il faut d'abord faire une analyse en composantes principales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Traiter les données (PCA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CSV.read(\"train.csv\")\n",
    "y_train = data[end]\n",
    "\n",
    "\n",
    "X_train = data[2:end-1] #omit id and diagnosis\n",
    "\n",
    "data_test = CSV.read(\"test.csv\")\n",
    "X_test = data_test[2:end]\n",
    "\n",
    "id_test = data_test[1]\n",
    "\n",
    "\n",
    "println(size(X_train))\n",
    "println(size(X_test))\n",
    "\n",
    "length_train = size(X_train)[1]\n",
    "length_test = size(X_train)[1]\n",
    "\n",
    "\n",
    "new_X = vcat(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Normalisation\n",
    "Nous avons testé un différent type de normalisation pour voir comment cela influait sur nos résultats. Par défaut, la fonction Normalize de Julia normalise en utilisant le Z-score. Mais il existe aussi le type UnitRangeTransform qui permet de normaliser nos données en donnant aux points extrêmes la même valeur pour chaque composante, malheureusement cela n’a pas amélioré notre score F1. \n",
    "\n",
    "Nous avons également recoder le Robust Scaler de la librairie Scikit Learn. Ce type de normalisation utilise plutôt l’écart interquartile, de sorte qu’il est robuste aux valeurs aberrantes. Voici l’équation de normalisation permettant de trouver la valeur normaliser $x_i$ à partir de $x'_i$.\n",
    "$$x'= \\frac{X_i - Q_1}{Q_3 - Q_1} $$\n",
    "\n",
    "Cette tentative n’a, elle non-plus pas amélioré nos résultats. Nous aurions également pu essayer d’autres méthodes de normalisation, mais nous avons préféré passer notre temps à explorer d’autres modèles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = convert(Array{Float64}, new_X)\n",
    "\n",
    "Z = standardize(X)\n",
    "\n",
    "# Décomposition en valeurs singulières de la matrice rectangulaire Z\n",
    "F = svd(Z)\n",
    "\n",
    "# Extraction de la matrice U\n",
    "U = F.U\n",
    "\n",
    "# Extraction de la matrice V\n",
    "V = F.V\n",
    "\n",
    "# Extraction des valeurs singulières\n",
    "γ = F.S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faire le modèle KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Premièrement, le KNN que nous avons implémenté utilise la distance euclidienne entre les points (aussi connu sous le nom de \"L2 norm\"). C'est important de le mentionné, car il y a plus d'une façon de faire le calcul d'une distance. Toutefois, nous avons choisis celle-là vu qu'elle est plus populaire. Ensuite, ce qu'il faut savoir c'est qu'un KNN, en général, nécessite que ces entrées soient normalisé. En effet, cela est du au fait que nous trouvons la distance entre deux points et que si les entrées ne sont pas normalisés, alors une différence dans l'orde de grandeur des variables explicatives va jouer sur l'importance des variables (une variable avec une plus grande orde de grandeur pourrait sembler plus importante ce qu'elle est vraiment vu que les distances de cette variable seront plus grandes). Finalement, pour trouver un K qui devrait donner un bon score, il est courant de faire du K-fold cross validation avec le training data pour savoir quel K pourrait être bon avec le testing set (celui qui pourrait bien généraliser). De plus, nous avons limités notre recherche du K optimal à des K impairs pour la simple raison que nous voulons que la classification se fasse avec une majorité (ce qui pourrait ne pas arriver si la moitié des K points les plus proches soient d'une certaine classe et l'autre moitié de l'autre classe)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function calculateDist(vec1, vec2)\n",
    "    dist = 0\n",
    "    taille = size(vec1)[1]\n",
    "    for i = 1:taille\n",
    "        dist += (vec1[i]-vec2[i])^2\n",
    "    end\n",
    "    \n",
    "    return dist\n",
    "end\n",
    "\n",
    "function findMin(n, tab, used_indexes)\n",
    "    mini_pos = 1\n",
    "    mini = tab[mini_pos]\n",
    "    \n",
    "    for i = 2:length(tab)\n",
    "        if (tab[i] < mini && !(i in used_indexes))\n",
    "            mini_pos = i\n",
    "            mini = tab[i]\n",
    "        end\n",
    "    end\n",
    "    return mini_pos\n",
    "end\n",
    "\n",
    "\n",
    "function findIndexesNSmallest(n, tab)\n",
    "    temp = copy(tab)\n",
    "    indexes = []\n",
    "    for i = 1:n\n",
    "        new_index = findMin(n, temp, indexes)\n",
    "        push!(indexes, new_index)\n",
    "    end\n",
    "    \n",
    "\n",
    "    return indexes\n",
    "end\n",
    "\n",
    "function predict(k, X_train, y_train, X_test) #works best with odd k    \n",
    "    nb_data = size(X_train)[1]\n",
    "    \n",
    "    distances = []\n",
    "    for elem in 1:nb_data\n",
    "        push!(distances, calculateDist(X_test, X_train[elem, :]))\n",
    "    end\n",
    "    \n",
    "    indexes_distances = findIndexesNSmallest(k, distances)\n",
    "    \n",
    "    nb_0 = 0\n",
    "    for index in indexes_distances\n",
    "        if (y_train[index] == 0)\n",
    "            nb_0 += 1\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return convert(Int8, (nb_0 < k - nb_0))\n",
    "    \n",
    "end\n",
    "\n",
    "function knn(k, X_train, y_train, X_test)\n",
    "    ans = []\n",
    "    for elem in 1:size(X_test)[1]\n",
    "        push!(ans, predict(k, X_train, y_train, X_test[elem, :]))\n",
    "    end\n",
    "    return ans\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## K-fold cross validation\n",
    "\n",
    "La validation croisée nous permettra d'utiliser toutes nos données comme ensemble de validation. Cela nous servira quand il sera temps d'évaluer la qualité du modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-cross validation\n",
    "function findAllIndexes(length, nb_blocks)\n",
    "    return [(convert(Int16, floor((i-1)*length/nb_blocks))+1, convert(Int16, floor(i*length/nb_blocks))) for i = 1:nb_blocks]\n",
    "end\n",
    "\n",
    "function countTFPN(t_label, predictions)\n",
    "    TP, FP, FN, TN = 0, 0, 0, 0\n",
    "    taille = size(t_label)[1]\n",
    "    for i = 1:taille\n",
    "        if(t_label[i] == 1 && predictions[i] == 1)\n",
    "            TP += 1\n",
    "        elseif(t_label[i] == 1 && predictions[i] == 0)\n",
    "            FN += 1\n",
    "        elseif(t_label[i] == 0 && predictions[i] == 1)\n",
    "            FP += 1\n",
    "        elseif(t_label[i] == 0 && predictions[i] == 0)\n",
    "            TN += 1\n",
    "        end\n",
    "            \n",
    "    end\n",
    "    return TP, FP, FN, TN\n",
    "end\n",
    "\n",
    "function computeMetrics(t_label, predictions)\n",
    "    TP, FP, FN, TN = countTFPN(t_label, predictions)\n",
    "    precision, recall, accuracy = (TP/(TP + FP)), (TP/(TP + FN)), ((TP+TN)/(TP + FP + FN + TN))\n",
    "    return [precision, recall, accuracy]\n",
    "end\n",
    "\n",
    "function split_train_test(X, y, index)\n",
    "    sub_X_train = [X[1 : index[1]-1, :]; X[index[2] : end, :]]\n",
    "    sub_X_test = X[index[1] : index[2], :]\n",
    "    sub_y_train = [y[1 : index[1]-1]; y[index[2] : end]]\n",
    "    true_y_test = y[index[1] : index[2]]\n",
    "    return sub_X_train, sub_X_test, sub_y_train, true_y_test\n",
    "end\n",
    "\n",
    "\n",
    "function KCrossValidation(k, X, y, nb_blocks = 30)\n",
    "    indexes = findAllIndexes(size(X)[1],nb_blocks)\n",
    "    ans = []\n",
    "    for interval = indexes\n",
    "        sub_X_train, sub_X_test, sub_y_train, true_y_test = split_train_test(X, y, interval)\n",
    "        sub_y_test =  knn(k, sub_X_train, sub_y_train, sub_X_test)\n",
    "        push!(ans, computeMetrics(true_y_test, sub_y_test))\n",
    "    end\n",
    "    temp = mean(ans)\n",
    "    return temp\n",
    "end\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trouver le K qui minimise l'erreur selon les métriques\n",
    "\n",
    "Le K correspond au nombre de voisins considérés. On prendra celui qui donne le meilleur score F1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat = γ[1] *U[:, 1]*V[:,1]'\n",
    "\n",
    "X_train = mat[1:length_train, :]\n",
    "X_test = mat[length_train+1:end, :]\n",
    "\n",
    "println(size(X_train))\n",
    "println(size(X_test))\n",
    "println(size(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spy_matrix = Array{AbstractFloat}(undef, 10, 10)\n",
    "spy_matrix_text = Array{Plots.PlotText}(undef, 10, 10)\n",
    "for j = 1:10\n",
    "    println(\"Index : \", j)\n",
    "    \n",
    "    mat = γ[1] *U[:, 1]*V[:,1]'\n",
    "    for k = 2:j\n",
    "        mat += γ[k] *U[:, k]*V[:,k]'\n",
    "    end\n",
    "    \n",
    "\n",
    "    X_train = mat[1:length_train, :]\n",
    "\n",
    "    X_test = mat[length_train+1:end, :]\n",
    "    metrics = []\n",
    "    gen_temp = 1:2:19\n",
    "    for i = 1:2:19\n",
    "        temp = KCrossValidation(i, X_train, y_train)\n",
    "        if (i ==  1)\n",
    "            metrics = [[elem] for elem = temp]\n",
    "        else\n",
    "            taille = size(temp)[1]\n",
    "            for index = 1:taille\n",
    "                push!(metrics[index], temp[index])\n",
    "            end\n",
    "        end\n",
    "\n",
    "    end\n",
    "    ks = [i for i = gen_temp]\n",
    "\n",
    "    \n",
    "    precision = metrics[1]\n",
    "    recall = metrics[2]\n",
    "    for index = 1:length(precision)\n",
    "        f1 = 2*(precision[index] * recall[index])/(precision[index] + recall[index])\n",
    "        println(\"F1 score \",index*2 - 1,  \"NN : \", f1)\n",
    "        spy_matrix[index,j] = f1\n",
    "        spy_matrix_text[index,j] = Plots.text(round(f1, digits=4),9)\n",
    "    end\n",
    "    \n",
    "end\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gadfly.set_default_plot_size(12cm, 12cm)\n",
    "Axis_k = [\"1\",\"3\",\"5\",\"7\",\"9\",\"11\",\"13\",\"15\",\"17\",\"19\"]\n",
    "Axis_PCA = [\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\", \"10\"]\n",
    "p = heatmap(Axis_PCA,Axis_k,spy_matrix,\n",
    "    ylabel =\"Value of K in the KNN\",\n",
    "    xlabel = \"Number of parameters conserved by the PCA\",\n",
    "    title = \"F1 score in function of the hyperparameters\",\n",
    "    c=:Greens\n",
    ")\n",
    "annotate!( vec(tuple.((1:length(Axis_PCA))'.-0.5, (1:length(Axis_k)).-0.5, spy_matrix_text)) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tentative et Amélioration possible \n",
    "\n",
    "Afin d’améliorer le résultat du KNN, nous avons expérimenté différentes stratégies qui avait le potentiel d'améliorer nos résultats en modifiant minimalement notre code. Par exemple, nous avons essayé d’autres métriques pour évaluer la distance. Pour, garder nos démarches simples, nous nous sommes contenté de tester les distances de Minkowski qui était très simples à coder à partir de notre fonction distance de base. \n",
    "\n",
    "Pour expliquer brièvement ces métriques, pour calculer la distance de Minkowski de degré P, il suffit de faire la somme des valeurs absolues des différences de composante pour chaque dimension de nos points et des mettre le résultat à la puissance P. \n",
    "\n",
    "Nous avons testé la distance de Minkowski de degré 1 à 4. De ces 4 tests, la distance de degré 2 qui correspond à la distance euclidienne classique donnait de loin le meilleur résultat. \n",
    "\n",
    "$$ D(Y,X) = (\\sum{\\lvert x_i - y_i \\rvert}^p)^{\\frac{1}{p}}$$\n",
    "\n",
    "Nous avons également utilisé un KNN dont la valeur significative de chaque voisin était proportionnelle à l’inverse de la distance par rapport au point que nous voulons évaluer. De cette manière les voisins les plus proches ont une  plus grande influence sur la classification que les voisins éloignés. Malheureusement, encore une fois cette tentative a fait baisser notre score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faire les prédictions sur le testing set \n",
    "\n",
    "Nous allons prendre un des K trouver précédemment qui avait obtenu un bon score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "\n",
    "mat = γ[1] *U[:, 1]*V[:,1]'\n",
    "for i = 2:7\n",
    "    mat += γ[i] *U[:, i]*V[:,i]'\n",
    "end\n",
    "X_train = mat[1:length_train, :]\n",
    "X_test = mat[length_train+1:end, :]\n",
    "\n",
    "y_test = knn(k, X_train, y_train, X_test)\n",
    "prediction = DataFrame(id = id_test, diagnosis = y_test)\n",
    "CSV.write(\"KNN.csv\",prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On en profite pour définir une fonction de prédiction plus générale, qui nous servira pour la section finale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function knn_predict(train, valid, k = 5, p = 7)\n",
    "    y_train = train[end]\n",
    "    X_train = train[2:end-1] #omit id and diagnosis\n",
    "    X_test = valid[2:end]\n",
    "\n",
    "    length_train = size(X_train)[1]\n",
    "\n",
    "    new_X = vcat(X_train, X_test)\n",
    "    \n",
    "    X = convert(Array{Float64}, new_X)\n",
    "    Z = standardize(X)\n",
    "\n",
    "    # Décomposition en valeurs singulières de la matrice rectangulaire Z\n",
    "    F = svd(Z)\n",
    "    U = F.U\n",
    "    V = F.V\n",
    "    γ = F.S\n",
    "\n",
    "    mat = γ[1] *U[:, 1]*V[:,1]'\n",
    "    for i = 2:p\n",
    "        mat += γ[i] *U[:, i]*V[:,i]'\n",
    "    end\n",
    "    X_train = mat[1:length_train, :]\n",
    "    X_test = mat[length_train+1:end, :]\n",
    "\n",
    "    return knn_counts(k, X_train, y_train, X_test)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion de la section KNN\n",
    "\n",
    "Le score obtenu avec le KNN est satisfaisant. Lorsque nous avons fait le K-fold cross validation nous avons pu voir que certaines valeurs de K et que certains nombres de paramètres conservés par le PCA obtiennent de meilleurs résultats que d'autres. Avec quelques essais sur Kaggle, nous avons déterminé que les hyper-paramètres qui donnent le meilleur résultat est lorsque le K = 5 et que le nombre de paramètres utilisés pour le PCA = 7. Le f1 score obtenu avec le K-fold cross validation est de 0.9344, mais lorsque nous l'avons rentré sur Kaggle, nous avons obtenu un score de 0.89743."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesien Naif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gadfly.set_default_plot_size(15cm, 10cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Chargement des données\n",
    "\n",
    "Assurez vous d'avoir télécharger les données dans le répertoire de ce calepin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CSV.read(\"train.csv\")\n",
    "first(data,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Séparation du jeu de données\n",
    "malign = filter(row -> row.diagnosis == 1, data)\n",
    "benign = filter(row -> row.diagnosis == 0, data)\n",
    "n₁ = size(malign, 1)\n",
    "n₀ = size(benign, 1)\n",
    "n = n₁ + n₀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loi prédictive\n",
    "\n",
    "Après avoir réalisé les calculs pour trouver la loi prédictive pour une loi normale considérant nos a priori non informatifs, on s'assurera qu'elle correspond aussi à une réalisation d'échantillonnage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loi_inconnue = Normal(5, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 150\n",
    "y = rand.(loi_inconnue for i=1:n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ȳ = mean(y)\n",
    "SST = sum((y .- ȳ).^2)\n",
    "s = SST / (n-1)\n",
    "mμ = LocationScale(ȳ, s/sqrt(n), TDist(n-1))\n",
    "mσ² = InverseGamma((n-1)/2, 1/2*SST)\n",
    "Gadfly.plot(\n",
    "    layer(x -> pdf(mμ, x), 0, 10, color=[\"mu\"]),\n",
    "    layer(x -> pdf(mσ², x), 0, 10, color=[\"sigma\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fucked_up_variance = (n+1) * (SST) / (n * (n-2))\n",
    "dist_pred = LocationScale(ȳ, sqrt(fucked_up_variance), TDist(n-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gibbs avec densités marginales\n",
    "quantity = 1000000\n",
    "ỹ = zeros(quantity)\n",
    "for i=1:quantity\n",
    "    μ_rand = rand(mμ)\n",
    "    σ_rand = sqrt(rand(mσ²))\n",
    "    ỹ[i] = rand(Normal(μ_rand, σ_rand))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gadfly.plot(\n",
    "    layer(x=y, alpha=[0.5],Geom.histogram(bincount=floor(sqrt(n)), density=true), Theme(default_color=colorant\"brown\")),\n",
    "    layer(x -> pdf(dist_pred, x), -30, 30, Theme(default_color=colorant\"black\")),\n",
    "    layer(x -> pdf(loi_inconnue, x), -30, 30, Theme(default_color=colorant\"red\")),\n",
    "    layer(x=ỹ, Geom.histogram(bincount=floor(sqrt(quantity)), density=true)),\n",
    "    Coord.cartesian(xmin=-5, xmax=15)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En noir : loi prédictive <br>\n",
    "En rouge: loi inconnue <br>\n",
    "En bleu: valeurs d'échantillonnage <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3. Application des lois aux données\n",
    "\n",
    "Pour chaque attribut, on représentera la distribution prédictive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul du modèle\n",
    "function loi_predictive(dataset::Array{Float64})\n",
    "    ȳ = mean(dataset)\n",
    "    n = length(dataset)\n",
    "    SST = sum((dataset .- ȳ).^2)\n",
    "    fucked_up_variance = (n+1) * (SST) / (n * (n-2))\n",
    "    return LocationScale(ȳ, sqrt(fucked_up_variance), TDist(n-2))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = length(data[!, :id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag = :radius\n",
    "pred_radius_0 = loi_predictive(benign[!, tag])\n",
    "pred_radius_1 = loi_predictive(malign[!, tag])\n",
    "Gadfly.plot(\n",
    "    layer(x->pdf(pred_radius_0, x), 0, 30, Theme(default_color=colorant\"black\")),\n",
    "    layer(x->pdf(pred_radius_1, x), 0, 30, Theme(default_color=colorant\"black\")),\n",
    "    layer(malign, x=tag, Geom.histogram(bincount=floor(sqrt(n₁)), density=true), color = [\"malign\"]),\n",
    "    layer(benign, x=tag, alpha=[0.75], Geom.histogram(bincount=floor(sqrt(n₀)), density=true), color = [\"benign\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = [:radius,:texture,:perimeter,:area,:smoothness,:compactness,\n",
    "    :concavity,:concave_points,:symmetry,:fractal_dimension]\n",
    "plots = []\n",
    "preds_0 = []\n",
    "preds_1 = []\n",
    "for tag in tags\n",
    "    pred_0 = loi_predictive(benign[!, tag])\n",
    "    pred_1 = loi_predictive(malign[!, tag])\n",
    "    push!(preds_0, pred_0)\n",
    "    push!(preds_1, pred_1)\n",
    "    max₀ = maximum(benign[!, tag])\n",
    "    max₁ = maximum(malign[!, tag])\n",
    "    push!(plots, Gadfly.plot(\n",
    "        layer(x->pdf(pred_0, x), 0, 1.2 * max₀, Theme(default_color=colorant\"black\")),\n",
    "        layer(x->pdf(pred_1, x), 0, 1.2 * max₁, Theme(default_color=colorant\"black\")),\n",
    "        layer(malign, x=tag, Geom.histogram(bincount=floor(sqrt(n₁)), density=true), color = [\"malign\"]),\n",
    "        layer(benign, x=tag, Geom.histogram(bincount=floor(sqrt(n₀)), density=true), color = [\"benign\"])\n",
    "    ))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots[10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si l'on utilise uniquement ces lois avec le modèle bayésien naïf (voir section 4), on obtient un score de 89% sur les données d'entrainement, et de 78% sur les données de test. On peux donc faire mieux!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Recherche de nouvelles lois\n",
    "\n",
    "La loi normale semble convenir pour la plupart des attributs. Néanmoins, pour la compacité et la concavité, il est clair que de meilleures lois peuvent être définies.\n",
    "\n",
    "Le temps nous étant compté, on utilisera cette fois la fonction *fit* pour approximer la loi a posteriori. Ainsi, au lieu d'utiliser la vraie loi prédicitve, on se servira d'estimateurs. On fera donc la même approximation que dans le devoir 8:\n",
    "\n",
    "$$f_{(\\tilde{X}_1|\\tilde{Y}=0)}(\\tilde{x}_1) \\approx f_{(\\tilde{X}_1|\\tilde{Y}=0, \\hat{\\boldsymbol{\\theta}}_{01})}(\\tilde{x}_1)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On commencera avec les lois qui nous semblent les plus probables sur la compacité des tumeurs bénignes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = fit(Gamma{Float64}, benign[!, :compactness])\n",
    "beta = fit(Beta{Float64}, benign[!, :compactness])\n",
    "lognormal = fit(LogNormal{Float64}, benign[!, :compactness])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Gadfly.plot(\n",
    "    layer(x -> pdf(gamma, x), 0, 0.5, color=[\"gamma\"]),\n",
    "    layer(x -> pdf(beta, x), 0, 0.5, color=[\"beta\"]),\n",
    "    layer(x -> pdf(lognormal, x), 0, 0.5, color=[\"lognormal\"]),\n",
    "    layer(x -> pdf(preds_0[6], x), 0, 0.5, Theme(default_color=colorant\"black\")),\n",
    "    layer(x=benign[!, :compactness], Geom.histogram(bincount = floor(sqrt(n₀)), density=true), \n",
    "        Theme(default_color=colorant\"lightblue\")),\n",
    "    Guide.xlabel(\"benign.compactness\"), Guide.ylabel(\"density\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ces trois lois semblent mieux décrire la compacité des tumeurs que la loi normale. Pour comparer les différents modèles, nous utiliserons le BIC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tous nos modèles ont deux paramètres\n",
    "# k=2\n",
    "df_bic = DataFrame(Model = String[], BIC=Float64[])\n",
    "push!(df_bic, [\"student\", loglikelihood(preds_0[6], benign[!, :compactness]) - log(n₀)])\n",
    "push!(df_bic, [\"gamma\", loglikelihood(gamma, benign[!, :compactness]) - log(n₀)])\n",
    "push!(df_bic, [\"beta\", loglikelihood(beta, benign[!, :compactness]) - log(n₀)])\n",
    "push!(df_bic, [\"lognormal\", loglikelihood(lognormal, benign[!, :compactness]) - log(n₀)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Devançant la loi gamma de presque trois points, le modèle le plus probable pour nos données est la lognormale, ce qui semble correspondre à ce qu'on peut voir sur le graphique plus haut. Nous allons maintenant appliquer ces mêmes modèles aux autres attributs. Nous en profiterons aussi pour voir la qualité de la loi prédictive par rapport à la loi normale avec paramètres estimés."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bic_malign = DataFrame(Student = Float64[], Normal=Float64[], Gamma=Float64[], Beta=Float64[], LogNormal=Float64[])\n",
    "for i=1:10\n",
    "    tag = tags[i]\n",
    "    y = malign[:, tag]\n",
    "    gammaValid = minimum(y) > 0\n",
    "    betaValid = minimum(y) >= 0 && maximum(y) <=1\n",
    "\n",
    "    push!(bic_malign, [\n",
    "        loglikelihood(preds_1[i], y) - log(n₀),\n",
    "        loglikelihood(fit(Normal, y), y) - log(n₀),\n",
    "        gammaValid ? loglikelihood(fit(Gamma{Float64}, y), y) - log(n₀) : -Inf,\n",
    "        betaValid ? loglikelihood(fit(Beta{Float64}, y), y) - log(n₀) : -Inf,\n",
    "        gammaValid ? loglikelihood(fit(LogNormal{Float64}, y), y) - log(n₀) : -Inf\n",
    "    ])\n",
    "end\n",
    "bic_malign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bic_benign = DataFrame(Student = Float64[], Normal=Float64[], Gamma=Float64[], Beta=Float64[], LogNormal=Float64[])\n",
    "for i=1:10\n",
    "    tag = tags[i]\n",
    "    y = benign[:, tag]\n",
    "    gammaValid = minimum(y) > 0\n",
    "    betaValid = minimum(y) >= 0 && maximum(y) <=1\n",
    "\n",
    "    push!(bic_benign, [\n",
    "        loglikelihood(preds_0[i], y) - log(n₀),\n",
    "        loglikelihood(fit(Normal, y), y) - log(n₀),\n",
    "        gammaValid ? loglikelihood(fit(Gamma{Float64}, y), y) - log(n₀) : -Inf,\n",
    "        betaValid ? loglikelihood(fit(Beta{Float64}, y), y) - log(n₀) : -Inf,\n",
    "        gammaValid ? loglikelihood(fit(LogNormal{Float64}, y), y) - log(n₀) : -Inf\n",
    "    ])\n",
    "end\n",
    "bic_benign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On voit que pour certaines variables, notamment la compacité (index 6), le BIC penche décisivement en faveur des autres modèles (différence supérieure à 2). On remarque au passage que, pour un modèle utilisant la loi normale, le facteur de Bayes entre la loi prédictive et l'estimation par maximum de vraisemblance penche toujours en faveur de la loi prédictive, mais rarement de façon décisive.\n",
    "\n",
    "Néanmoins, certaines des valeurs de concavité (index 7 et 8) sont en dessous de 0 dans les tumeurs bénignes. C'est plutôt dommage, surtout que visuellement, la loi normale était plutôt mauvaise pour modéliser ces valeurs! De plus, selon le BIC, ces modèles conviennent mieux aux valeurs des tumeurs malignes, comme on peut le voir ci-dessous:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = malign[:, :concavity]\n",
    "\n",
    "gamma = fit(Gamma{Float64}, y)\n",
    "beta = fit(Beta{Float64}, y)\n",
    "lognormal = fit(LogNormal{Float64}, y)\n",
    "\n",
    "Gadfly.plot(\n",
    "    layer(x -> pdf(gamma, x), 0, 0.5, color=[\"gamma\"]),\n",
    "    layer(x -> pdf(beta, x), 0, 0.5, color=[\"beta\"]),\n",
    "    layer(x -> pdf(lognormal, x), 0, 0.5, color=[\"lognormal\"]),\n",
    "    layer(x -> pdf(preds_1[7], x - 0.01), 0, 0.5, Theme(default_color=colorant\"black\")),\n",
    "    layer(x=y, Geom.histogram(bincount = floor(sqrt(n₀)), density=true), \n",
    "        Theme(default_color=colorant\"lightblue\")),\n",
    "    Guide.xlabel(\"malign.concavity\"), Guide.ylabel(\"density\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On tentera donc de gérer ces valeurs négatives, pour utiliser les lois proposées sur les données de concavité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum(benign[!, tags[7]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "minimum(benign[!, tags[8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count(val-> val <= 0, benign[:, :concavity])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count(val-> val <= 0, benign[:, :concave_points])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Très peu de valeurs sont inférieures ou égales à 0, et celles qui le sont sont très proches de 0. On peut donc se permettre de les ramener à une valeur juste au-dessus de 0.\n",
    "\n",
    "Il faudra toutefois se rappeler d'effectuer la même transformation aux données de test!\n",
    "\n",
    "On commencera avec la concavité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = benign[:, :concavity]\n",
    "y = map(val -> val <= 0 ? 0.0001 : val, y)\n",
    "\n",
    "gamma = fit(Gamma{Float64}, y)\n",
    "beta = fit(Beta{Float64}, y)\n",
    "lognormal = fit(LogNormal{Float64}, y)\n",
    "\n",
    "Gadfly.plot(\n",
    "    layer(x -> pdf(gamma, x), 0, 0.5, color=[\"gamma\"]),\n",
    "    layer(x -> pdf(beta, x), 0, 0.5, color=[\"beta\"]),\n",
    "    layer(x -> pdf(lognormal, x), 0, 0.5, color=[\"lognormal\"]),\n",
    "    layer(x -> pdf(preds_0[7], x), 0, 0.5, Theme(default_color=colorant\"black\")),\n",
    "    layer(x=y, Geom.histogram(bincount = floor(sqrt(n₀)), density=true), \n",
    "        Theme(default_color=colorant\"lightblue\")),\n",
    "    Guide.xlabel(\"benign.concavity\"), Guide.ylabel(\"density\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tous nos modèles ont deux paramètres\n",
    "# k=2\n",
    "df_bic = DataFrame(Model = String[], BIC=Float64[])\n",
    "push!(df_bic, [\"student\", loglikelihood(preds_0[7], y) - log(n₀)])\n",
    "push!(df_bic, [\"gamma\", loglikelihood(gamma, y) - log(n₀)])\n",
    "push!(df_bic, [\"beta\", loglikelihood(beta, y) - log(n₀)])\n",
    "push!(df_bic, [\"lognormal\", loglikelihood(lognormal, y) - log(n₀)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tous ces modèles sont nettements suprérieures à la loi normale. On remarque toutefois sur le graphique qu'ils ne semblent pas très bien suivre les données. On tentera donc un autre technique pour inclure les valeurs négative : décaler les données.\n",
    "\n",
    "Le décalage de 0.01 a été choisi visuellement comme celui qui permet aux lois de mieux suivre les données. On pourrait faire un travail pour maximiser la vraisemblance de ce paramètre, mais pour l'instant, comme nous voulons vraiment juste améliorer nos prédictions par rapport à la loi normale, nous nous sommes contentés de cette approximation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decalage = 0.01\n",
    "y = benign[:, :concavity] .+ decalage\n",
    "\n",
    "gamma = fit(Gamma{Float64}, y)\n",
    "beta = fit(Beta{Float64}, y)\n",
    "lognormal = fit(LogNormal{Float64}, y)\n",
    "\n",
    "Gadfly.plot(\n",
    "    layer(x -> pdf(gamma, x), 0, 0.5, color=[\"gamma\"]),\n",
    "    layer(x -> pdf(beta, x), 0, 0.5, color=[\"beta\"]),\n",
    "    layer(x -> pdf(lognormal, x), 0, 0.5, color=[\"lognormal\"]),\n",
    "    layer(x -> pdf(preds_0[7], x - decalage), 0, 0.5, Theme(default_color=colorant\"black\")),\n",
    "    layer(x=y, Geom.histogram(bincount = floor(sqrt(n₀)), density=true), \n",
    "        Theme(default_color=colorant\"lightblue\")),\n",
    "    Guide.xlabel(\"benign.concavity\"), Guide.ylabel(\"density\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "decalage = 0.01\n",
    "y = benign[:, :concavity] .+ decalage\n",
    "# Pour calculer le BIC avec ces nouvelles données, on devra adapter la loi prédictive\n",
    "pred = loi_predictive(y)\n",
    "\n",
    "df_bic = DataFrame(Model = String[], BIC=Float64[])\n",
    "push!(df_bic, [\"student\", loglikelihood(pred, y) - log(n₀)])\n",
    "# Le rajout du paramètre de décalage rajoute un paramètre à notre modèle!\n",
    "# Cela n'affecte pas la loi normale, puisque ce paramètre correspond à la moyenne.\n",
    "# k=3\n",
    "push!(df_bic, [\"gamma\", loglikelihood(gamma, y) - 3/2 * log(n₀)])\n",
    "push!(df_bic, [\"beta\", loglikelihood(beta, y) - 3/2 * log(n₀)])\n",
    "push!(df_bic, [\"lognormal\", loglikelihood(lognormal, y) - 3/2 * log(n₀)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La gamma de la première mise à niveau a à peu près le même BIC que la lognormae de la seconde. On peut donc choisir l'un ou l'autre de ces modèles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On poursuit avec les points concaves. On appliquera la même démarche que pour la concavité."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = benign[:, :concave_points]\n",
    "y = map(val -> val <= 0 ? 0.0001 : val, y)\n",
    "\n",
    "gamma = fit(Gamma{Float64}, y)\n",
    "beta = fit(Beta{Float64}, y)\n",
    "lognormal = fit(LogNormal{Float64}, y)\n",
    "\n",
    "Gadfly.plot(\n",
    "    layer(x -> pdf(gamma, x), 0, 0.2, color=[\"gamma\"]),\n",
    "    layer(x -> pdf(beta, x), 0, 0.2, color=[\"beta\"]),\n",
    "    layer(x -> pdf(lognormal, x), 0, 0.2, color=[\"lognormal\"]),\n",
    "    layer(x -> pdf(preds_0[8], x), 0, 0.2, Theme(default_color=colorant\"black\")),\n",
    "    layer(x=y, Geom.histogram(bincount = floor(sqrt(n₀)), density=true), \n",
    "        Theme(default_color=colorant\"lightblue\")),\n",
    "    Guide.xlabel(\"benign.concave_points\"), Guide.ylabel(\"density\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tous nos modèles ont deux paramètres\n",
    "# k=2\n",
    "df_bic = DataFrame(Model = String[], BIC=Float64[])\n",
    "push!(df_bic, [\"student\", loglikelihood(preds_0[8], y) - log(n₀)])\n",
    "push!(df_bic, [\"gamma\", loglikelihood(gamma, y) - log(n₀)])\n",
    "push!(df_bic, [\"beta\", loglikelihood(beta, y) - log(n₀)])\n",
    "push!(df_bic, [\"lognormal\", loglikelihood(lognormal, y) - log(n₀)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = benign[:, :concave_points]\n",
    "y = y .+ 0.01\n",
    "\n",
    "gamma = fit(Gamma{Float64}, y)\n",
    "beta = fit(Beta{Float64}, y)\n",
    "lognormal = fit(LogNormal{Float64}, y)\n",
    "\n",
    "Gadfly.plot(\n",
    "    layer(x -> pdf(gamma, x), 0, 0.2, color=[\"gamma\"]),\n",
    "    layer(x -> pdf(beta, x), 0, 0.2, color=[\"beta\"]),\n",
    "    layer(x -> pdf(lognormal, x), 0, 0.2, color=[\"lognormal\"]),\n",
    "    layer(x -> pdf(preds_0[8], x-0.01), 0, 0.2, Theme(default_color=colorant\"black\")),\n",
    "    layer(x=y, Geom.histogram(bincount = floor(sqrt(n₀)), density=true), \n",
    "        Theme(default_color=colorant\"lightblue\")),\n",
    "    Guide.xlabel(\"benign.concave_points\"), Guide.ylabel(\"density\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bic = DataFrame(Model = String[], BIC=Float64[])\n",
    "push!(df_bic, [\"student\", loglikelihood(loi_predictive(y), y) - log(n₀)])\n",
    "push!(df_bic, [\"gamma\", loglikelihood(gamma, y) - 3/2 * log(n₀)])\n",
    "push!(df_bic, [\"beta\", loglikelihood(beta, y) - 3/2 * log(n₀)])\n",
    "push!(df_bic, [\"lognormal\", loglikelihood(lognormal, y) - 3/2 * log(n₀)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Choix du modèle\n",
    "\n",
    "Donnant suite à notre analyse exploratoire, nous avons choisi les modèles que seront utlisés pour le bayésien naïf. Nous en avons aussi profité pour sélectionner les variables, en fonction de leur pertinence et de la colinéarité.\n",
    "\n",
    "Les variables perimeter, area et concave_points seront retirées ainf de diminuer la multicolinéarité. On enlève aussi fractal_dimensions, qui n'est visuellement pas pertinente.\n",
    "\n",
    "Cela nous laisse avec les variables suivantes, que nous modéliserons avec le modèle qui présente de le meilleur BIC. En cas de doute ($\\Delta$BIC < 2), on choisit un modèle qui convient aux deux ensembles de données, par souci de cohérence.\n",
    "- radius : Normale\n",
    "- texture : LogNormale\n",
    "- smoothness : LogNormale\n",
    "- compactness : LogNormale\n",
    "- concavity : Gamma (avec modification des valeurs négatives)\n",
    "- symmetry : LogNormale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [1, 2, 5, 6, 7, 9]\n",
    "\n",
    "for i=[2, 5, 6, 9]\n",
    "    preds_0[i] = fit(LogNormal, benign[:, tags[i]])\n",
    "    preds_1[i] = fit(LogNormal, malign[:, tags[i]])\n",
    "end\n",
    "\n",
    "preds_0[7] = fit(Gamma, map(val-> val <= 0 ? 0.0001 : val, benign[:, :concavity]))\n",
    "preds_1[7] = fit(Gamma, malign[:, :concavity])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i=variables\n",
    "    y₁ = malign[:, tags[i]]\n",
    "    y₀ = benign[:, tags[i]]\n",
    "    plots[i] = Gadfly.plot(\n",
    "        layer(x->pdf(preds_0[i], x), 0, 1.2 * maximum(y₀), Theme(default_color=colorant\"black\")),\n",
    "        layer(x->pdf(preds_1[i], x), 0, 1.2 * maximum(y₁), Theme(default_color=colorant\"black\")),\n",
    "        layer(x=y₁, Geom.histogram(bincount=floor(sqrt(n₁)), density=true), color = [\"malign\"]),\n",
    "        layer(x=y₀, Geom.histogram(bincount=floor(sqrt(n₀)), density=true), color = [\"benign\"])\n",
    "    )\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots[7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plots[9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Probabilité d'une tumeur maligne\n",
    "\n",
    "On utilisera un modèle bayésien naïf à plusieurs variables pour déterminer si une tumeur est maligne ou bénigne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "α = 1\n",
    "β = 1\n",
    "n₀ = size(benign, 1)\n",
    "n₁ = size(malign, 1)\n",
    "n = n₀ + n₁\n",
    "p₀ = (β + n₀)/(α + β + n)\n",
    "p₁ = (α + n₁)/(α + β + n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function vraisemblance_maligne(row::DataFrameRow, selected_variables)\n",
    "    q₀ = log(p₀)\n",
    "    q₁ = log(p₁)\n",
    "    \n",
    "    for i=selected_variables\n",
    "        q₀ += log(pdf(preds_0[i], row[tags[i]]))\n",
    "        \n",
    "        q₁ += log(pdf(preds_1[i], row[tags[i]]))\n",
    "    end\n",
    "\n",
    "    return q₁ - q₀\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = map(row -> vraisemblance_maligne(row, variables), eachrow(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = results .> 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctrate(data[!, :diagnosis], predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Cross validation\n",
    "\n",
    "Nous nous sommes demandés si enlever des variables colinéaires améliorait effectivement les prédictions. Pour cela, il faut séprarer notre ensemble de données entre entrainement et validation, puisque si l'utilisation de toutes les variables va toujours améliorer notre précision sur l'ensemble d'entrainement, elle peut la réduire sur une ensemble de test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Il faut aussi choisir des lois pour les autres variables que nous avions rejetées.\n",
    "\n",
    "- perimeter : Normale\n",
    "- area : Normale\n",
    "- concave_points : Gamma avec recentrage des données\n",
    "- fractal_dimension : LogNormale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function bayesian_predict(m_train, b_train, valid, variables)\n",
    "    # Lois normales\n",
    "    for attr=[1, 3, 4]\n",
    "        preds_0[attr] = loi_predictive(b_train[:, tags[attr]])\n",
    "        preds_1[attr] = loi_predictive(m_train[:, tags[attr]])\n",
    "    end\n",
    "\n",
    "    # Lois lognormales\n",
    "    for attr=[2, 5, 6, 9, 10]\n",
    "        preds_0[attr] = fit(LogNormal, b_train[:, tags[attr]])\n",
    "        preds_1[attr] = fit(LogNormal, m_train[:, tags[attr]])\n",
    "    end\n",
    "\n",
    "    # Lois gamma\n",
    "    # Pour la concavité des tumeurs bénignes, on modifie les points sous 0\n",
    "    # On n'applique pas ces modifications aux tumeurs malignes, puisqu'aucune valeur ne se trouve sous 0\n",
    "    y = map(val -> val <=0 ? 0.00001 : val, b_train[:, :concavity])\n",
    "    preds_0[7] = fit(Gamma, y)\n",
    "    preds_1[7] = fit(Gamma, m_train[:, :concavity])\n",
    "    # Pour les points concaves des tumeurs bénignes, on décale tout de 0.01\n",
    "    # Ces modifications devront aussi s'appliquer aux tumeurs malignes\n",
    "    preds_0[8] = fit(Gamma, b_train[:, :concave_points] .+ 0.01)\n",
    "    preds_1[8] = fit(Gamma, m_train[:, :concave_points] .+ 0.01)\n",
    "\n",
    "    # Il faut appliquer les mêmes changements à l'ensemble de test\n",
    "    valid = copy(valid)\n",
    "    valid[!, :concavity] = map(val -> val <=0 ? 0.00001 : val, valid[:, :concavity])\n",
    "    valid[!, :concave_points] = valid[:, :concave_points] .+ 0.01\n",
    "\n",
    "    results = DataFrame(id = Int64[], predictions = Float64[])\n",
    "    map(row->push!(results, [row.id, vraisemblance_maligne(row, variables)]), eachrow(valid))\n",
    "    return results\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On réutilisera la méthode `findAllIndexes` du KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function bayesian_split_data(i::Int64, nb_blocks::Int64)\n",
    "    malign_indexes = findAllIndexes(n₁, nb_blocks)\n",
    "    benign_indexes = findAllIndexes(n₀, nb_blocks)\n",
    "    \n",
    "    m_range = malign_indexes[i][1]:malign_indexes[i][2]\n",
    "    malign_valid = malign[m_range, :]\n",
    "    malign_train = malign[Not(m_range), :]\n",
    "\n",
    "    b_range = benign_indexes[i][1]: benign_indexes[i][2]\n",
    "    benign_valid = benign[b_range, :]\n",
    "    benign_train = benign[Not(b_range), :]\n",
    "    \n",
    "    valid = append!(malign_valid, benign_valid)\n",
    "    \n",
    "    return malign_train, benign_train, valid\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut maintenant appliquer nos modèles à chaque bloc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rates_all = []\n",
    "rates_selected = []\n",
    "selected_variables = [1, 2, 5, 6, 7, 9]\n",
    "nb_blocks = 5\n",
    "for i=1:nb_blocks\n",
    "    m_train, b_train, valid = bayesian_split_data(i, nb_blocks)\n",
    "    \n",
    "    # Prédictions avec variables sélectionnées\n",
    "    results = bayesian_predict(m_train, b_train, valid, selected_variables)\n",
    "    predictions = results.predictions .> 0\n",
    "    push!(rates_selected, correctrate(predictions, valid.diagnosis))\n",
    "    \n",
    "    # Prédictions avec toutes les variables\n",
    "    results = bayesian_predict(m_train, b_train, valid, 1:10)\n",
    "    predictions = results.predictions .> 0\n",
    "    push!(rates_all, correctrate(predictions, valid.diagnosis))\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(rates_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean(rates_selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notre modèle ne semble pas être trop sensible à la colinéarité, ou aux variables presque inutiles. On peut donc se peremttre d'utiliser l'ensemble des variables pour le modèle final."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Application du modèle à l'ensemble de test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = CSV.read(\"test.csv\")\n",
    "first(test, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cette fois-ci, l'ensemble d'entrainement repose sur toutes les données disponibles\n",
    "results = bayesian_predict(malign, benign, test, 1:10)\n",
    "first(results, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = results.predictions .> 0\n",
    "mean(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = DataFrame(id = test[:,:id], diagnosis = predictions)\n",
    "CSV.write(\"bayes_naif.csv\",final)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ce modèle a obtenu une précision de 80% sur l'ensemble de test ¯\\\\\\_(ツ)_/¯"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyse critique\n",
    "\n",
    "Le travail sur la loi prédictive n'était pas vraiment nécessaire finalement, puisque d'autres modèles que la loi normale se sont assez souvent révélés de meilleure qualité, et même quand la loi normale est le meilleure modèle, la loi prédictive n'est pas significativement meilleure que l'estimation des paramètres d'après le BIC.\n",
    "\n",
    "À bien y penser, il n'est peut-être  pas très bon de séparer l'ensemble de données entre tumeurs malignes et bénignes avant même de faire la validation croisée. Cette séparation a été notamment faite pour ne pas avoir besoin de recalculer p₀ et p₁, même si leur valeur n'est plus exacte pour la validation, et pour éviter d'avoir un cas extrême où il y a très peu de valeurs dans l'une ou l'autre des catégories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 4: Régression logistique\n",
    "\n",
    "Nous avons déterminés lors de l'analyse de composantes/l'analyse de multicolinéarité que nous avons fait dans un autre document quelles variables il fallait utiliser pour minimiser les problèmes de multicolinéarité et quelles variables conserver. Pour débuter, on utilise donc les variables: \"radius\", \"texture\", \"smoothness\", \"compactness\", \"concavity\" et \"symmetry\" comme variables explicatives dans le modèle linéaire généralisé."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_vars = tags[[1, 2, 5, 6, 7, 9]]\n",
    "Term(:diagnosis) ~ sum(term.(selected_vars))\n",
    "function trainGlmWith(df, formula=Term(:diagnosis) ~ sum(term.(selected_vars)))\n",
    "    return glm(formula, df,  Bernoulli(), LogitLink())\n",
    "end\n",
    "\n",
    "trainGlmWith(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimation par maximum de la vraisemblance du modèle de régression logistique\n",
    "Pour voir la performance de ce modèle, on réalisera aussi une validation croisée."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function glm_split_train_test(df, index)\n",
    "    train = df[Not(index[1]:index[2]), :]\n",
    "    test = df[index[1]:index[2], :]\n",
    "    return train, test\n",
    "end\n",
    "\n",
    "function glm_kcross(df, k, formula=Term(:diagnosis) ~ sum(term.(selected_vars)))\n",
    "    indexes = findAllIndexes(size(df, 1), k)\n",
    "    θ̂  = Float64[]\n",
    "    for interval = indexes\n",
    "        train, test = glm_split_train_test(df, interval)\n",
    "        M = trainGlmWith(train, formula)\n",
    "        θ̂ᵢ = GLM.predict(M, test)\n",
    "        append!(θ̂, θ̂ᵢ)\n",
    "    end\n",
    "    return θ̂\n",
    "end\n",
    "\n",
    "θ̂ = glm_kcross(data, 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mesure de la qualité du modèle\n",
    "\n",
    "Supposons que l'on prédit que la tumeur est maligne si θ̂ > 1/2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Le taux de bonnes prédictions\n",
    "ŷ = zeros(Int64,length(data.diagnosis))\n",
    "ŷ[θ̂ .> 1/2] .= 1 \n",
    "\n",
    "println(\"Le taux de bonnes prédictions est de \", round(correctrate(data.diagnosis, ŷ), digits=3),\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul du taux de vrais positifs et de faux positifs pour un seuil de 1/2.\n",
    "\n",
    "r = roc(data.diagnosis, θ̂, 1/2)\n",
    "\n",
    "println(\"La sensibilité est de \", round(recall(r), digits=3))\n",
    "println(\"La spécificité est de \", round(precision(r), digits=3))\n",
    "println(\"Le score F1 est de \", round(f1score(r), digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcul de l'aire sous la courbe ROC\n",
    "A = auc(data.diagnosis, θ̂)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage de la courbe ROC\n",
    "rocplot(data.diagnosis, θ̂)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recherche du meilleur modèle\n",
    "\n",
    "Puisqu'on n'a que 10 variables,  on peut se permettre de tester toutes les possiblités. Cela devrait prendre entre 5 et 10 minutes! On se servira de l'aire sous la courbe ROC pour définir le meilleur modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = DataFrame(Variables = Array{Symbol}[], AUC = Float64[])\n",
    "\n",
    "# Premier modèle : aucune variable\n",
    "push!(models, [[], 0.5])\n",
    "\n",
    "# On teste tous les modèles possibles\n",
    "for var in tags\n",
    "    for model in eachrow(models)\n",
    "        vars = copy(model[:Variables])\n",
    "        push!(vars, var)\n",
    "\n",
    "        formula = Term(:diagnosis) ~ sum(term.(vars))\n",
    "        θ̂ = glm_kcross(data, 15, formula)\n",
    "        AUC = auc(data.diagnosis, θ̂)\n",
    "\n",
    "        push!(models, [vars, AUC])\n",
    "    end\n",
    "end\n",
    "\n",
    "# Le meilleur modèle est sélectionné avec la plus grande aire sous la courbe ROC\n",
    "sort!(models, :AUC, rev=true)\n",
    "top10 = first(models, 10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On se servira donc du modèle incluant toutes les variables sauf radius, compactness et concavity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = models[1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "θ̂ = glm_kcross(data, 10, Term(:diagnosis) ~ sum(term.(best_model.Variables)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rocplot(data.diagnosis, θ̂)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choix du seuil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(x -> f1score(roc(data.diagnosis, θ̂, x)), 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot(x -> correctrate(θ̂ .> x, data.diagnosis), 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tant qu'il reste autour de 0.5, le seuil ne smeble pas avoir une influence majeure sur la qualité de nos prédictions, du moins sur notre ensemble de validation. Nous allon donc garder un seuil non biaisé de 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "println(\"Le taux de bonnes prédictions est de \", round(correctrate(θ̂ .> 1/2, data.diagnosis), digits=3),\".\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 5: Comparaison de modèles\n",
    "\n",
    "Dans cette partie, nous nous sommes demandé si l'on pouvait utiliser plusieurs modèles pour améliorer nos prédictions, en comparant les résultats qui diffèrent entre eux.\n",
    "\n",
    "En comparant deux modèles, il y a 3 cas de figure :\n",
    "- Les modèles ont tous les deux raison\n",
    "- Les modèles ont tous les deux tort\n",
    "- Les modèles se contredisent\n",
    "\n",
    "En analysant les données corresondant à chacun de ces cas, on pourrait savoir quand prioriser un modèle par rapport à l'autre."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour pouvoir quantifier l'incertitude du modèle KNN, on lui fera plutôt donner la moyenne du diagnostic de ses plus proches voisin que la prédiction finale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function predict_counts(k, X_train, y_train, X_test) #works best with odd k    \n",
    "    nb_data = size(X_train)[1]\n",
    "    \n",
    "    distances = []\n",
    "    for elem in 1:nb_data\n",
    "        push!(distances, calculateDist(X_test, X_train[elem, :]))\n",
    "    end\n",
    "    \n",
    "    indexes_distances = findIndexesNSmallest(k, distances)\n",
    "    \n",
    "    nb_0 = 0\n",
    "    for index in indexes_distances\n",
    "        if (y_train[index] == 0)\n",
    "            nb_0 += 1\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return (nb_0, k-nb_0)\n",
    "    \n",
    "end\n",
    "\n",
    "function knn_counts(k, X_train, y_train, X_test)\n",
    "    ans = []\n",
    "    for elem in 1:size(X_test)[1]\n",
    "        push!(ans, predict_counts(k, X_train, y_train, X_test[elem, :]))\n",
    "    end\n",
    "    return ans\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Génération des prédictions avec validation croisée"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNN_predictions = []\n",
    "bayesian_predictions = DataFrame(id = Int64[], predictions = Float64[])\n",
    "\n",
    "nb_blocks = 15\n",
    "indexes = findAllIndexes(size(X_train)[1], nb_blocks)\n",
    "\n",
    "\n",
    "for i=1:nb_blocks\n",
    "    m_train, b_train, valid = bayesian_split_data(i, nb_blocks)\n",
    "    \n",
    "    # Prédictions avec toutes les variables\n",
    "    results = bayesian_predict(m_train, b_train, valid, 1:10)\n",
    "    append!(bayesian_predictions, results)\n",
    "    \n",
    "    sub_X_train, sub_X_test, sub_y_train, true_y_test = split_train_test(X_train, y_train, indexes[i])\n",
    "    sub_y_test = knn_counts(5, sub_X_train, sub_y_train, sub_X_test)\n",
    "    append!(KNN_predictions, sub_y_test)\n",
    "\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ces prédictions sont dans l'ordre des indexes\n",
    "# Les tuples sont donnés sous la forme [voisin_benin, voisin_malin]\n",
    "KNN_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# La prédiction est la moyenne des diagnostics\n",
    "KNN_predictions = map(tuple -> tuple[2] / (tuple[1] + tuple[2]), KNN_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sort!(bayesian_predictions, :id)\n",
    "first(bayesian_predictions, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GLM\n",
    "glm_predictions = glm_kcross(data, 15, Term(:diagnosis) ~ sum(term.(best_model.Variables)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut maintenant rassembler ces prédictions dans nos données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CSV.read(\"train.csv\")\n",
    "insertcols!(data, 13, :knn => KNN_predictions)\n",
    "insertcols!(data, 14, :bayesian => bayesian_predictions.predictions)\n",
    "insertcols!(data, 15, :glm => glm_predictions)\n",
    "names(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctrate(data.knn .> 0.5, data.bayesian .> 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctrate(data.knn .> 0.5, data.glm .> 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctrate(data.glm .> 0.5, data.bayesian .> 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les modèles sont en désaccord sur certaines valeurs. C'est une bonne nouvelle, car on peut trouver une manière de les départager, et ainsi d'obtenir une meilleure précision sur nos données.\n",
    "\n",
    "On commencera par voir sur combien de données nos modèles sont en désaccord, et sur combien ils se trompent tous."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_disagree = filter(row -> !((row.knn > 0.5) == (row.bayesian > 0.5) == (row.glm > 0.5)), data)\n",
    "select(data_disagree, [:knn, :bayesian, :glm, :diagnosis])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all_wrong = filter(row -> (row.knn > 0.5) == (row.bayesian > 0.5) == (row.glm > 0.5)\n",
    "                                && (row.diagnosis == 1) != (row.knn > 0.5) , data)\n",
    "select(data_all_wrong, [:knn, :bayesian, :glm, :diagnosis])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans les données sujettes à désaccord, on peut remarquer que les modèles sont généralement assez peu sûrs d'eux (la probabilité, ou le log de la probabilité, sont proches du seuil de séparation). Ce n'est pas toujours le cas quand ils se trompent tous, où certaines valeurs extrêmes échappent complètement à leur contrôle.\n",
    "\n",
    "Une première approche pourrait être de faire voter ces différents modèles, afin de faire varier les sources d'erreurs induites par nos différentes approches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function vote(df::DataFrame, knn_th, bayes_log_th, glm_th)\n",
    "    vote_results = Int64[]\n",
    "    for row in eachrow(df)\n",
    "        knn_pred = row.knn > knn_th\n",
    "        bayes_pred = row.bayesian > bayes_log_th\n",
    "        glm_pred = row.glm > glm_th\n",
    "        vote = mean([knn_pred, bayes_pred, glm_pred]) .> 0.5\n",
    "        push!(vote_results, vote)\n",
    "    end\n",
    "    return vote_results\n",
    "end\n",
    "\n",
    "correctrate(vote(data, 0.5, 0.5, 0.5), data.diagnosis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On a améliorer un peu notre qualité de prédiction, mais pas de beaucoup! Une autre option pourrait être d'attribuer un certain coefficient à chaque modèle, ce qu'on peut faire en utilisant la régression. Cette approche n'est pas rigoureuse, puisqu'on utilise deux fois les données, mais nous sommes désespérés d'obtenir un bon score sur kaggle :-("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M = glm(@formula(diagnosis ~ knn + bayesian + glm), data,  Bernoulli(), LogitLink())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctrate(GLM.predict(M, data) .> 0.5, data.diagnosis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C'est un peu mieux! On peut entrainer notre modèle sur l'ensemble des données et prédire l'ensemble de test à partir de ce nouveau modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = CSV.read(\"train.csv\")\n",
    "test = CSV.read(\"test.csv\")\n",
    "insertcols!(test, 12, :knn => map(tuple -> tuple[2] / (tuple[1] + tuple[2]), knn_predict(data, test)))\n",
    "insertcols!(test, 13, :bayesian => sort!(bayesian_predict(malign, benign, test, 1:10), :id).predictions)\n",
    "glm_model = glm(Term(:diagnosis) ~ sum(term.(best_model.Variables)), data, Bernoulli(), LogitLink())\n",
    "insertcols!(test, 14, :glm => GLM.predict(glm_model, test))\n",
    "names(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_predictions = GLM.predict(M, test)\n",
    "CSV.write(\"blend.csv\", DataFrame(id = test.id, diagnosis = final_predictions .> 0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "88 % :-/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Julia 1.0.5",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
